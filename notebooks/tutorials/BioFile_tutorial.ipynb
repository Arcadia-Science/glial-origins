{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277d4721-49c3-4511-b8b3-dab7705162c5",
   "metadata": {},
   "source": [
    "# BioFile handling tutorial\n",
    "\n",
    "Working with single-cell datasets across multiple species can be complicated!  \n",
    "The __`BioFile`__ handling functions in this repo are meant to help streamline the process of working with single-cell data across multiple species.  \n",
    "This notebook serves as a basic tutorial for the BioFile class and related functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678b3002-dd79-4890-8f1f-a87366a218f3",
   "metadata": {},
   "source": [
    "# 0. Import\n",
    "\n",
    "To get started:\n",
    "1. First, import some necessary dependencies.  \n",
    "2. Use `sys.path.append` to place the necessary functions into your python `$PATH`.\n",
    "2. Then, import the functions from `biofile_handling.py`, `string_functions.py`, and `install_locs.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5320dc-57a4-408d-a3be-16f45c961b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard python packages\n",
    "import pandas as pd\n",
    "import subprocess, os, sys, dill\n",
    "\n",
    "# add the utils and env directories to the path\n",
    "import sys\n",
    "sys.path.append('../../utils/')\n",
    "sys.path.append('../../env/')\n",
    "\n",
    "# import functions from utils directory files\n",
    "from string_functions import *\n",
    "from biofile_handling import *\n",
    "\n",
    "# import paths to software installs from env\n",
    "from install_locs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55d8cf-a058-48c9-ae9d-55d5ae6854ff",
   "metadata": {},
   "source": [
    "# 1. Create a BioFileDocket\n",
    "\n",
    "Before interacting with files, it's important to create a `BioFileDocket`.  \n",
    "This class acts as a container which tracks all files in your dataset.\n",
    "Creating a new `BioFileDocket` only requires two parameters:\n",
    "1. `species`: the name of your species in the format `Genus_species`\n",
    "2. `conditions`: a unique identifier for your dataset as an alphanumeric string (no spaces or underscores).  \n",
    "   This could include details like tissue type and sample number (e.g. `brain1`).  \n",
    "   This string should be __unique__ and not repeated for a different dataset.\n",
    "   \n",
    "Upon creation, a `BioFileDocket` will create a directory on your machine if it does not already exist.  \n",
    "Files created for this dataset will be saved into that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c505b9c6-1e3e-4ef7-acd2-5e457130e621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/glial-origins/output/Gspe_tutorial/ already exists\n",
      "Files will be saved into /home/ec2-user/glial-origins/output/Gspe_tutorial/\n"
     ]
    }
   ],
   "source": [
    "# Specify the name of the species in 'Genus_species' format\n",
    "# This should contain an underscore\n",
    "species = 'Genus_species'\n",
    "\n",
    "# Specify any particular identifying conditions, eg tissue type:\n",
    "# Must be alphanumeric; can't contain special characters\n",
    "conditions = 'tutorial'\n",
    "\n",
    "sample_BFD = BioFileDocket(species, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8793742-3045-4635-8646-cc5d5fedfb22",
   "metadata": {},
   "source": [
    "#### Tip\n",
    "\n",
    "A `BioFileDocket` has some useful parameters which you can access via a dot operator.  \n",
    "For example, to get the `directory` where files in the `BioFileDocket` are stored, see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506f4618-adcd-4506-9b6e-7ff7aab2ebfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/glial-origins/output/Gspe_tutorial/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_BFD.directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eb60e5-2315-43f2-bcd0-436f3a86446b",
   "metadata": {},
   "source": [
    "# 2. Create a BioFile from scratch\n",
    "\n",
    "Once you have a `BioFileDocket`, you can start creating `BioFile` objects.  \n",
    "These objects can be used to keep track of files on your local system and link them to each other.\n",
    "\n",
    "A simple way to use the `BioFile` object system is to reference a file that already exists on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f329d283-bb34-4b95-b466-73207f0f003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does this file exist? True\n"
     ]
    }
   ],
   "source": [
    "# This line will create a file for us to reference.\n",
    "subprocess.run(['touch', sample_BFD.directory + 'samplefile.txt'])\n",
    "\n",
    "# Creating a BioFile object minimally requires a SampleDict.\n",
    "# This object carries information about species, conditions, and directory.\n",
    "# If you create a file without downloading from a URL or from S3, you must also specify a filename.\n",
    "\n",
    "# Conventionally, you should use sample_BFD.sampledict.\n",
    "#   This passes the needed SampleDict object from the BioFileDocket.\n",
    "# The BioFile class will also accept a SampleDict object you generate from scratch.\n",
    "biofile_object = BioFile(\n",
    "    sampledict = sample_BFD.sampledict,\n",
    "    filename = 'samplefile.txt'\n",
    ")\n",
    "\n",
    "# You can double-check to make sure your BioFile object points to the right place.\n",
    "print('Does this file exist?', biofile_object.exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadee625-f859-489f-b364-fcdbd60dc5d6",
   "metadata": {},
   "source": [
    "#### Tip\n",
    "\n",
    "`BioFile` objects have numerous built-in functionalities.  \n",
    "You can learn more about these using the built-in `help()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca15b40-f61d-47ea-ac1a-b377178b7f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BioFile in module biofile_handling:\n",
      "\n",
      "class BioFile(builtins.object)\n",
      " |  BioFile(sampledict: biofile_handling.SampleDict, filename='', url=None, protocol=None, s3uri=None, unzip=True)\n",
      " |  \n",
      " |  BioFile objects collect metadata about specific biological filetypes.\n",
      " |  \n",
      " |  Args:\n",
      " |      sampledict (:obj:`SampleDict`): a SampleDict object from the BioFileDocket.\n",
      " |      filename (str, optional): the name of the file.\n",
      " |      url (str, optional): when downloading a file on object creation, pass a string url along with a protocol.\n",
      " |      protocol (str, optional): passed along with a url for automatic download on object creation.\n",
      " |      s3uri (str, optional): the s3uri of the file, if downloading from s3 upon object creation.\n",
      " |      unzip (bool, optional): whether or not to unzip a file on download. Defaults to True.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sampledict: biofile_handling.SampleDict, filename='', url=None, protocol=None, s3uri=None, unzip=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  add_s3uri(self, s3uri: str)\n",
      " |      Adds an s3uri to the BioFile object if it doesn't already exist.\n",
      " |  \n",
      " |  get_from_s3(self, overwrite=False)\n",
      " |      Downloads the BioFile from AWS S3.\n",
      " |      \n",
      " |      Args:\n",
      " |          overwrite (bool): decide whether to overwrite existing files. Defaults to False.\n",
      " |  \n",
      " |  get_from_url(self, url: str, protocol: str, filename='', unzip=True)\n",
      " |      Downloads the BioFile from a URL using a chosen protocol, unzipping optionally.\n",
      " |      \n",
      " |      Args:\n",
      " |          url (str): url of the file.\n",
      " |          protocol (str): protocol to be used for download.\n",
      " |          filename (str, optional): name of file to be saved. If empty, will generate name from URL.\n",
      " |          unzip (bool): decide whether to unzip if it is a zipped file. Defaults to True.\n",
      " |  \n",
      " |  push_to_s3(self, overwrite=False)\n",
      " |      Uploads the BioFile to AWS S3.\n",
      " |      \n",
      " |      Args:\n",
      " |          overwrite (bool): decide whether to overwrite existing files. Defaults to False.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  exists\n",
      " |      bool: checks whether the file currently exists.\n",
      " |  \n",
      " |  filetype\n",
      " |      str: infers filetype using the string after the final `.` in filename.\n",
      " |  \n",
      " |  path\n",
      " |      str: path to the file, including the filename.\n",
      " |  \n",
      " |  sampledict\n",
      " |      :obj:`SampleDict`: a SampleDict object for the file.\n",
      " |  \n",
      " |  species_prefix\n",
      " |      str: runs prefixify(species).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BioFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f32e6-7c00-4680-a8f5-6a8e55de7a11",
   "metadata": {},
   "source": [
    "# 3. Create a BioFile by downloading from a URL or S3 URI\n",
    "\n",
    "Often when working with publicly available data, files are be downloaded from a URL.  \n",
    "\n",
    "You can certainly download a file manually using your preferred method and then capture it in a `BioFile` object, as above.  \n",
    "However, the `BioFile` object has methods for file downloading from a URL as well.  \n",
    "Using these methods, you can create a `BioFile` object and immediately download that file to your system.  \n",
    "\n",
    "Currently, the `get_from_url` method allows you to download using the `curl` or `wget` protocols.  \n",
    "The `get_from_url` method is automatically called when you pass a `url` and `protocol` variable at the creation of a `BioFile` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7e3e84-c02b-4623-bc58-bd78091a3d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "\n",
      "world\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To download using curl or wget, you can specify a filename, url, and protocol.\n",
    "\n",
    "# Below, we download a file using curl.\n",
    "biofile_object_curl = BioFile(\n",
    "    sampledict = sample_BFD.sampledict,\n",
    "    filename = 'testfile1.txt',\n",
    "    url = 'https://raw.githubusercontent.com/Arcadia-Science/glial-origins/das/biofile-revision-dev/utils/tut/testfile1.txt?token=GHSAT0AAAAAAB3ZLBCF4IP73QREWKMWAPXUY4P2IVQ',\n",
    "    protocol = 'curl'\n",
    ")\n",
    "\n",
    "# If this succeeded, it should print \"Hello\"\n",
    "with open(biofile_object_curl.path, 'r') as f:\n",
    "    print(f.read())\n",
    "    \n",
    "# Here, we download a file using wget\n",
    "biofile_object_wget = BioFile(\n",
    "    sampledict = sample_BFD.sampledict,\n",
    "    filename = 'testfile2.txt',\n",
    "    url = 'https://raw.githubusercontent.com/Arcadia-Science/glial-origins/das/biofile-revision-dev/utils/tut/testfile2.txt?token=GHSAT0AAAAAAB3ZLBCF4MWQWGUBQCGFENP4Y4P2JFA',\n",
    "    protocol = 'wget'\n",
    ")\n",
    "\n",
    "# If this succeeded, it should print \"world\"\n",
    "with open(biofile_object_wget.path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff3435-1b0a-4024-b17e-a11bd2c2ddb7",
   "metadata": {},
   "source": [
    "### Downloading from AWS S3\n",
    "\n",
    "`BioFile` objects also support downloading files using an AWS S3 URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c5fdbb-b3fa-46df-a45f-768759c1fc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://arcadia-reference-datasets/tutorials/testfile3.txt to ../../output/Gspe_tutorial/testfile3.txt\n"
     ]
    }
   ],
   "source": [
    "# Here, we create a BioFile object by downloading from AWS S3 using a URI.\n",
    "\n",
    "# If the URL or URI ends in a filename, you don't have to specify the filename variable;\n",
    "#   the filename will automatically be set to whatever string follows the final '/' in the URL string.\n",
    "# We can omit the 'filename' field because the s3uri can be neatly parsed into a filename.\n",
    "biofile_object_s3 = BioFile(\n",
    "    sampledict = sample_BFD.sampledict,\n",
    "    s3uri = 's3://arcadia-reference-datasets/tutorials/testfile3.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb3b29-98bd-496e-9d03-fcddfd8ad4d8",
   "metadata": {},
   "source": [
    "# 4. Place BioFile objects into BioFileDocket\n",
    "To keep track of your files, you need to place your `BioFile` objects into the `BioFileDocket` you created.\n",
    "\n",
    "You can add these files individually or as a list.  \n",
    "To see the list of file objects listed by filename, you can use the `.files` dot operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699e7984-ee01-41cd-8367-a0bcad951d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samplefile.txt': <biofile_handling.BioFile at 0x7ff81c0ef910>,\n",
       " 'testfile1.txt': <biofile_handling.BioFile at 0x7ff76b1ea620>,\n",
       " 'testfile2.txt': <biofile_handling.BioFile at 0x7ff81c0efa60>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a single BioFile object to tracked files.\n",
    "sample_BFD.add_file(biofile_object)\n",
    "\n",
    "# Add a list of BioFile objects to tracked files.\n",
    "sample_BFD.add_files([biofile_object_curl, biofile_object_wget])\n",
    "\n",
    "# List the names of files and the associated BioFile objects.\n",
    "display(sample_BFD.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c9454-d6c7-43d0-9c43-2a0e07e001f7",
   "metadata": {},
   "source": [
    "### Keyfiles\n",
    "\n",
    "Generic files added to the `.files` attribute are tracked but not automatically uploaded.  \n",
    "You can use this to store files whose provenance is important but are easily generated.  \n",
    "\n",
    "For files that you expect to use repeatedly and which you want to be automatically uploaded, you should use the `add_keyfile` method.  \n",
    "- For a given keyfile, you can specify a key, e.g. `aws_testfile`.\n",
    "- Keyfiles can be accessed directly using the dot operator, e.g. `sample_BFD.aws_testfile`.\n",
    "- This method is particularly useful if you are working across species.  \n",
    "  For example, you could access all of the `.genome_fasta` files from multiple species programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6912e7c-b023-403b-9814-31c7904c52fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species': 'Genus_species',\n",
       " 'conditions': 'tutorial',\n",
       " 'directory': '/home/ec2-user/glial-origins/output/Gspe_tutorial/',\n",
       " 'files': {'samplefile.txt': <biofile_handling.BioFile at 0x7ff81c0ef910>,\n",
       "  'testfile1.txt': <biofile_handling.BioFile at 0x7ff76b1ea620>,\n",
       "  'testfile2.txt': <biofile_handling.BioFile at 0x7ff81c0efa60>},\n",
       " 'metadata': <biofile_handling.dummy_object at 0x7ff81c0efd60>,\n",
       " 'aws_testfile': <biofile_handling.BioFile at 0x7ff81c0efac0>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'filename': 'testfile3.txt',\n",
       " 'species': 'Genus_species',\n",
       " 'conditions': 'tutorial',\n",
       " 'directory': '/home/ec2-user/glial-origins/output/Gspe_tutorial/',\n",
       " 's3uri': 's3://arcadia-reference-datasets/tutorials/testfile3.txt'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/glial-origins/output/Gspe_tutorial/testfile3.txt'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a keyfile using the 'aws_testfile' key\n",
    "sample_BFD.add_keyfile('aws_testfile', biofile_object_s3)\n",
    "\n",
    "# Display the attributes of the BioFileDocket\n",
    "#   Note that 'aws_testfile' has its own key-value pair.\n",
    "display(vars(sample_BFD))\n",
    "\n",
    "# Display the attributes of the aws_testfile using dot operations.\n",
    "display(vars(sample_BFD.aws_testfile))\n",
    "\n",
    "# Get the path to the aws_testfile using dot operations.\n",
    "display(sample_BFD.aws_testfile.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a8db2-b6ee-4512-9f1f-908ff6e3fa5d",
   "metadata": {},
   "source": [
    "# 5. Pickling the `BioFileDocket`\n",
    "\n",
    "When programming interactively, it's possible to lose track of your variables when you shut down a session.  \n",
    "To preserve the `BioFileDocket` and its associated files, you can use the `.pickle()` method.  \n",
    "This creates a binary file that stores the `BioFileDocket` and all of its included `BioFile` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7749aed6-9e20-4cdf-bc15-5ace1764564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling the BioFileDocket is very simple!\n",
    "sample_BFD.pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c149775-4b58-4f5e-ab82-19220e4a5810",
   "metadata": {},
   "source": [
    "### Unpickling the `BioFileDocket`\n",
    "\n",
    "From a `.pkl` file, you can retrieve your previous variables.  \n",
    "A `BioFileDocket` object places its `.pkl` file in a set location with a set name.  \n",
    "Using `.unpickle()` allows you to load the object again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1e8505-b08b-476a-93f2-497b9189cd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species': 'Genus_species',\n",
       " 'conditions': 'tutorial',\n",
       " 'directory': '/home/ec2-user/glial-origins/output/Gspe_tutorial/',\n",
       " 'files': {'samplefile.txt': <biofile_handling.BioFile at 0x7ff76b1eac20>,\n",
       "  'testfile1.txt': <biofile_handling.BioFile at 0x7ff76b1ea0b0>,\n",
       "  'testfile2.txt': <biofile_handling.BioFile at 0x7ff76b1eae30>},\n",
       " 'metadata': <biofile_handling.dummy_object at 0x7ff76b1eaf50>,\n",
       " 'aws_testfile': <biofile_handling.BioFile at 0x7ff76b1eabc0>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creates a new BioFileDocket by unpickling your previous .pkl file.\n",
    "new_sample_BFD = sample_BFD.unpickle()\n",
    "display(vars(new_sample_BFD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042def88-51db-405b-90ed-4b03c14cbc1f",
   "metadata": {},
   "source": [
    "### Pushing the `.pkl` file to AWS S3\n",
    "\n",
    "You can also save the `.pkl` file for a `BioFileDocket` to a set location on AWS S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914905c0-0d81-44b9-8ae9-6afb6cc7038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gspe_tutorial_sample_BioFileDocket.pkl already exists in S3 bucket, skipping upload. set overwrite = True to overwrite the existing file.\n"
     ]
    }
   ],
   "source": [
    "# This saves the .pkl file to S3\n",
    "sample_BFD.push_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bb25e-0a3c-466e-9e4a-e416d63fe5dc",
   "metadata": {},
   "source": [
    "### Getting a `.pkl` file from AWS S3\n",
    "\n",
    "Conversely, you can pull a .pkl file from S3 and extract its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb385e37-7c5c-4786-9599-bac7e95e8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file Gspe_tutorial_sample_BioFileDocket.pkl already exists at /home/ec2-user/glial-origins/output/Gspe_tutorial/Gspe_tutorial_sample_BioFileDocket.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'species': 'Genus_species',\n",
       " 'conditions': 'tutorial',\n",
       " 'directory': '/home/ec2-user/glial-origins/output/Gspe_tutorial/',\n",
       " 'files': {'samplefile.txt': <biofile_handling.BioFile at 0x7ff76b1eab60>,\n",
       "  'testfile1.txt': <biofile_handling.BioFile at 0x7ff76b1ea9e0>,\n",
       "  'testfile2.txt': <biofile_handling.BioFile at 0x7ff76b1eaa40>},\n",
       " 'metadata': <biofile_handling.dummy_object at 0x7ff76b1ea7a0>,\n",
       " 'aws_testfile': <biofile_handling.BioFile at 0x7ff76b1ea170>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_sample_BFD2 = sample_BFD.get_from_s3().unpickle()\n",
    "\n",
    "display(vars(new_sample_BFD2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba68928-ddcc-4baf-968e-f2f34d3d2719",
   "metadata": {},
   "source": [
    "#### Tip: `.pkl` file uniqueness\n",
    "\n",
    "The `.get_from_s3()` and `.unpickle()` methods look for a `.pkl` file based on the `species` and `conditions` of a `BioFileDocket`.  \n",
    "This means that you don't have to have any information in your local `BioFileDocket` to start with â€“ as long as it exists on S3, you can retrieve the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e6cbdd-3cf4-4e56-97c9-7c32f1e21fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/glial-origins/output/Gspe_tutorial/ already exists\n",
      "Files will be saved into /home/ec2-user/glial-origins/output/Gspe_tutorial/\n",
      "file Gspe_tutorial_sample_BioFileDocket.pkl already exists at /home/ec2-user/glial-origins/output/Gspe_tutorial/Gspe_tutorial_sample_BioFileDocket.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'species': 'Genus_species',\n",
       " 'conditions': 'tutorial',\n",
       " 'directory': '/home/ec2-user/glial-origins/output/Gspe_tutorial/',\n",
       " 'files': {'samplefile.txt': <biofile_handling.BioFile at 0x7ff81da3bd60>,\n",
       "  'testfile1.txt': <biofile_handling.BioFile at 0x7ff76b1eace0>,\n",
       "  'testfile2.txt': <biofile_handling.BioFile at 0x7ff76b1ea140>},\n",
       " 'metadata': <biofile_handling.dummy_object at 0x7ff76b1ea680>,\n",
       " 'aws_testfile': <biofile_handling.BioFile at 0x7ff76b1ea6b0>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating an empty BioFileDocket using just the species and conditions,\n",
    "#   then pulling the .pkl file based on those identifiers to fill the BioFileDocket\n",
    "species = 'Genus_species'\n",
    "conditions = 'tutorial'\n",
    "new_sample_BFD3 = BioFileDocket(species, conditions).get_from_s3().unpickle()\n",
    "\n",
    "display(vars(new_sample_BFD3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26499576-5dab-4d85-9b35-452664be1b27",
   "metadata": {},
   "source": [
    "# 6. Systematically transferring files in a `BioFileDocket` to and from AWS S3\n",
    "\n",
    "The `BioFileDocket` can upload all associated keyfiles from S3 programmatically.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b7af795-34cc-4c9f-a8ba-62a7399955c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testfile3.txt already exists in S3 bucket, skipping upload. set overwrite = True to overwrite the existing file.\n"
     ]
    }
   ],
   "source": [
    "new_sample_BFD3.local_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d739f28-8b73-4861-b245-61f3735b9914",
   "metadata": {},
   "source": [
    "Conversely, it can also download all files from S3 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50aebbd6-94c8-47df-bf2a-1bdf0714a1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file testfile3.txt already exists at /home/ec2-user/glial-origins/output/Gspe_tutorial/testfile3.txt\n"
     ]
    }
   ],
   "source": [
    "new_sample_BFD3.s3_to_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3e03a-c136-4d31-8865-7c7ff35ad4bb",
   "metadata": {},
   "source": [
    "# XX. Create a MultiSpeciesDocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a601e12-6d26-4968-9fb2-fabeb804bb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/glial-origins/output/FbarGspeHwor_tutorial_Testing/ already exists\n"
     ]
    }
   ],
   "source": [
    "# Specify the name of the species folder in Amazon S3\n",
    "# This should contain an underscore\n",
    "species_dict = {\n",
    "    'Genus_species': 'tutorial',\n",
    "    'Foo_bar': 'tutorial',\n",
    "    'Hello_world': 'tutorial'\n",
    "}\n",
    "\n",
    "# Specify any particular identifying conditions, eg tissue type:\n",
    "# Must be alphanumeric; can't contain special characters\n",
    "global_conditions = 'tutorial'\n",
    "\n",
    "analysis_type = 'Testing'\n",
    "\n",
    "sample_MSD = MultiSpeciesBioFileDocket(species_dict, global_conditions, analysis_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b19a65-c8f6-4da5-9a0e-2936bdcd4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_MSD.pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "626af72d-be5d-4fe9-9566-2b1f4f91ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_MSD.add_keyfile('blah', biofile_object_curl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d897f9d-167c-44a5-a2b5-a539182c93e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7e668-5aeb-407c-9ae1-efd725389472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
